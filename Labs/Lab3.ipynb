{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 3: Supervised Learning I - Regression Models\n",
    "\n",
    "In this lab, we will cover the following topics:\n",
    "1. Regression models for both continuous and binary outcomes:\n",
    "    * Linear\n",
    "    * Polynomial \n",
    "    * Logistic \n",
    "2. Apply regularization techniques to manage overfitting\n",
    "\n",
    "Each section includes basic implementation and questions for further exploration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Regression Models \n",
    "### 1.1 Linear Regression for Continuous Outcomes\n",
    "\n",
    "We will start by implementing a linear regression model to predict continuous outcomes. We will also explore different parameters and visualize the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Generate synthetic data\n",
    "np.random.seed(42)\n",
    "X = 2 * np.random.rand(100, 1)\n",
    "y = 4 + 3 * X + np.random.randn(100, 1)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a linear regression model\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = lin_reg.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "print(f\"R^2 Score: {r2}\")\n",
    "\n",
    "# Plot the results\n",
    "plt.scatter(X_test, y_test, color='blue', label='Actual')\n",
    "plt.plot(X_test, y_pred, color='red', label='Predicted')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('y')\n",
    "plt.title('Linear Regression')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LinearRegression?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions for Exploration\n",
    "\n",
    "1. How does changing the `test_size` parameter in the `train_test_split` function affect the model performance?\n",
    "2. What happens to the model performance if you add noise to the data?\n",
    "3. How does the model performance change if you use a different random seed for data generation?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Polynomial Regression for Continuous Outcomes\n",
    "\n",
    "Next, we will implement a polynomial regression model to predict continuous outcomes. We will also explore different parameters and visualize the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# Generate synthetic data\n",
    "np.random.seed(42)\n",
    "X = 2 * np.random.rand(100, 1) - 1\n",
    "y = 4 + 3 * X + 2 * X**2 + np.random.randn(100, 1)\n",
    "\n",
    "# Transform the data to include polynomial features\n",
    "poly_features = PolynomialFeatures(degree=2, include_bias=False)\n",
    "X_poly = poly_features.fit_transform(X)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_poly, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a linear regression model on the polynomial features\n",
    "poly_reg = LinearRegression()\n",
    "poly_reg.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = poly_reg.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "print(f\"R^2 Score: {r2}\")\n",
    "\n",
    "# Plot the results\n",
    "plt.scatter(X[:, 0], y, color='blue', label='Actual')\n",
    "plt.scatter(X_test[:, 0], y_pred, color='red', label='Predicted')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('y')\n",
    "plt.title('Polynomial Regression')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PolynomialFeatures?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions for Exploration\n",
    "\n",
    "1. How does changing the degree of the polynomial features affect the model performance?\n",
    "2. What happens to the model performance if you add higher-degree polynomial features?\n",
    "3. How does the model performance change if you use a different random seed for data generation?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Logistic Model for Binary Outcomes\n",
    "\n",
    "Next, we will implement a logistic regression model to predict binary outcomes. We will also explore different parameters and visualize the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, roc_curve, auc, precision_recall_curve, average_precision_score\n",
    "\n",
    "# Generate synthetic data\n",
    "X, y = make_classification(n_samples=1000, n_features=20, n_classes=2, weights=[0.9, 0.1], random_state=42)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train a logistic regression model\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "# Predict probabilities\n",
    "y_scores = log_reg.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Compute ROC curve and ROC area\n",
    "fpr, tpr, _ = roc_curve(y_test, y_scores)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Compute Precision-Recall curve and PR area\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_scores)\n",
    "average_precision = average_precision_score(y_test, y_scores)\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n",
    "\n",
    "# Plot Precision-Recall curve\n",
    "plt.figure()\n",
    "plt.plot(recall, precision, color='blue', lw=2, label='Precision-Recall curve (area = %0.2f)' % average_precision)\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve')\n",
    "plt.legend(loc='lower left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LogisticRegression?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions for Exploration\n",
    "\n",
    "1. How does changing the `C` parameter in the `LogisticRegression` model affect the model performance?\n",
    "2. What happens to the ROC curve and AUC score when you change the class weights?\n",
    "3. How does the model performance change if you use a different random seed for data generation?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Regularization Techniques to Manage Overfitting\n",
    "\n",
    "Finally, we will apply regularization techniques such as Ridge and Lasso regression to manage overfitting. We will also explore different parameters and visualize the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet\n",
    "\n",
    "# Generate synthetic data\n",
    "np.random.seed(42)\n",
    "X = 2 * np.random.rand(100, 1)\n",
    "y = 4 + 3 * X + np.random.randn(100, 1)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a Ridge regression model\n",
    "ridge_reg = Ridge(alpha=1.0)\n",
    "ridge_reg.fit(X_train, y_train)\n",
    "\n",
    "# Train a Lasso regression model\n",
    "lasso_reg = Lasso(alpha=0.1)\n",
    "lasso_reg.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_ridge = ridge_reg.predict(X_test)\n",
    "y_pred_lasso = lasso_reg.predict(X_test)\n",
    "\n",
    "# Evaluate the models\n",
    "mse_ridge = mean_squared_error(y_test, y_pred_ridge)\n",
    "r2_ridge = r2_score(y_test, y_pred_ridge)\n",
    "mse_lasso = mean_squared_error(y_test, y_pred_lasso)\n",
    "r2_lasso = r2_score(y_test, y_pred_lasso)\n",
    "print(f\"Ridge Regression - Mean Squared Error: {mse_ridge}, R^2 Score: {r2_ridge}\")\n",
    "print(f\"Lasso Regression - Mean Squared Error: {mse_lasso}, R^2 Score: {r2_lasso}\")\n",
    "\n",
    "# Plot the results\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(X_test, y_test, color='blue', label='Actual')\n",
    "plt.plot(X_test, y_pred_ridge, color='red', label='Ridge Predicted')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('y')\n",
    "plt.title('Ridge Regression')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(X_test, y_test, color='blue', label='Actual')\n",
    "plt.plot(X_test, y_pred_lasso, color='green', label='Lasso Predicted')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('y')\n",
    "plt.title('Lasso Regression')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ridge?\n",
    "Lasso?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions for Exploration\n",
    "\n",
    "1. How does changing the `alpha` parameter in the `Ridge` and `Lasso` models affect the model performance?\n",
    "2. What happens to the model performance if you use different values of `alpha`?\n",
    "3. Try implementing an `ElasticNet` model in the cell above.\n",
    "    * How does it compare to the `Ridge` and `Lasso` models?\n",
    "    * How does changing `alpha` affect the model performance? \n",
    "4. How does the model performance change if you use a different random seed for data generation?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extensions\n",
    "\n",
    "1. Create new features from the existing ones (e.g., interaction terms, polynomial features) and evaluate their impact on model performance.\n",
    "2. How does feature scaling (e.g., standardization, normalization) affect the performance of linear, polynomial, and logistic models?\n",
    "3. Compare the performance of linear, polynomial, and logistic models on the same dataset using various evaluation metrics (e.g., R^2, MSE, ROC AUC)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
